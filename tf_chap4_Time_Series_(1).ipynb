{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_chap4_Time_Series (1).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAuJtwxtDmeWBG7iMIfqoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinhyung426/deeplearning.ai/blob/main/tf_chap4_Time_Series_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwbZuou5ndhi"
      },
      "source": [
        "# Tensorflow\r\n",
        "\r\n",
        "## Part 4. Time Series\r\n",
        "\r\n",
        "## (1) Basics of Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u7TXAWcotm9"
      },
      "source": [
        "**1. Time Series**\r\n",
        "  - ordered sequence of values that are usually equally spaced over time\r\n",
        "  - anything that has a time factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1rMiT0lo025"
      },
      "source": [
        "**2. Types of Time Series**\r\n",
        "\r\n",
        "**1) Univariate Time Serie**s\r\n",
        "  - Only one variable is varying over time\r\n",
        "  \r\n",
        "  ex) stock price\r\n",
        "\r\n",
        "**2) Multivariate Time Series**\r\n",
        "  - More than one variables are varying over time\r\n",
        "  ex) birth vs death rate, co2 concentration vs global temperature\r\n",
        "  ex) movement of a body (series of a univariate or a combined multivariate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJFUwm_oH2A-"
      },
      "source": [
        "# Input Shape\r\n",
        "\r\n",
        "**input_shape = (batch_size, timestep, dimension)**\r\n",
        " \r\n",
        " (1) dimension = 1  ----->  Univariate Time Series\r\n",
        "\r\n",
        " (2) dimension > 1  ----->  Multivariate Time Series\r\n",
        "\r\n",
        " (3) timestep => all timestep is possible\r\n",
        " \r\n",
        " (4) batch_size => don't have to specify it in keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSVp5nHRMzDx"
      },
      "source": [
        "**3. Functions of Analyzing Time Series**\r\n",
        "\r\n",
        "**1) Imputation**\r\n",
        "  - **Using present data to forecast past data**\r\n",
        "  - Filling holes and gaps (imputed valuesë¡œ fill up)\r\n",
        "\r\n",
        "**2) Detect Abnomalies**\r\n",
        "\r\n",
        "- ex. detect hacker attacks\r\n",
        "\r\n",
        "**3) Spot Patterns**\r\n",
        "\r\n",
        "- ex. recognize words or subwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8kqMaFXNQ1U"
      },
      "source": [
        "**4. Common Patterns in Time Series**\r\n",
        "\r\n",
        "**1) Trend**\r\n",
        "  - Upwards facing trend\r\n",
        "  - Downwards facing trend\r\n",
        "\r\n",
        "**2) Seasonality**\r\n",
        "  - patterns repeat every predictable intervals\r\n",
        "\r\n",
        "  - ex. peek on weekends, down on weekdays\r\n",
        "\r\n",
        "**3) Combination of Trend and Seasonality**\r\n",
        "   \r\n",
        "   - ex. overall upwards but local peaks\r\n",
        "\r\n",
        "**4) Simple Random data with noise**\r\n",
        "  - not much we can do\r\n",
        "\r\n",
        "**5) Autocorrelated Time Series**\r\n",
        "  - data that follows a predictable shape, even if the scale is different\r\n",
        "  - it correlates with a delayed copy of itself, often called a lag\r\n",
        "  - no trend, no seasonality but the entire series isn't random\r\n",
        "  - ex. memory as steps are dependent on previous ones but spikes (innvoations) appear at random timesteps\r\n",
        "\r\n",
        "**6) Multiple Autocorrelated Series**\r\n",
        "  - decay can be interrupted with another pulse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y5bYqHPs72D"
      },
      "source": [
        "**5. Real World Data & Machine Learning**\r\n",
        "\r\n",
        "- **Real World** : Trend + Seasonality + Autocorrelation + Noise\r\n",
        "- **Machine Learning** : spot patterns and make predictions (except noise) under the assumption that patterns in the past will continue in the future"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pcA8Hxwt37E"
      },
      "source": [
        "**6. Stationary VS Non-Stationary Time Series**\r\n",
        "\r\n",
        "**(1) Stationary Time Series**\r\n",
        "  - behavior doesn't change over time \r\n",
        "  - more data results in better prediction\r\n",
        "\r\n",
        "**(2) Non-Stationary Time Series**\r\n",
        "  - behavior changes over time\r\n",
        "\r\n",
        "  ex. Positive trend may change to negative trend due to unexpected events like financial crisis or tech innovations\r\n",
        "  - optimal time window for training the model will vary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaGqvzQ_t3-Y"
      },
      "source": [
        "**7. Fixed Partitioning VS Roll Forward Partitioning**\r\n",
        "\r\n",
        "**(1) Fixed Partitioning**\r\n",
        "- each period contains entire seasonality\r\n",
        "\r\n",
        "- [Step 1] Train with train data\r\n",
        "- [Step 2] Evaluate with val data\r\n",
        "- [Step 3] Retrain with train, val data\r\n",
        "- [Step 4] Evaluate with test data\r\n",
        "- [Step 5] Train with data including test data since test data is the most recent data and therefore the strongest signal\r\n",
        "\r\n",
        "**(2) Roll Forward Partitioning**\r\n",
        "- [Step 1] Start with short training period and gradually increase it\r\n",
        "- [Step 2] Then, we use it to forecast the following day in the validation period\r\n",
        "- [Step 3] Doing fixed partitioning a number of times, and continually refining model as such\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnEk4EQet4CC"
      },
      "source": [
        "**8. Metrics**\r\n",
        "\r\n",
        "- errors = forecast - true\r\n",
        "\r\n",
        "(1) **MSE** = np.sqaure(errors).mean()\r\n",
        "  - use when big errors are not good\r\n",
        "  - use when focusing on outliers\r\n",
        "\r\n",
        "(2) **RMSE** = np.sqrt(mse)\r\n",
        "\r\n",
        "(3) **MAE** = np.abs(errors).mean()\r\n",
        "\r\n",
        "(4) **MAPE** = np.abs(errors / x_valid).mean()\r\n",
        "  - ratio\r\n",
        "\r\n",
        "(5) **Huber Loss**\r\n",
        "  - doesn't focus on outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOUmJOgb0g3s"
      },
      "source": [
        "**9. Moving Average**\r\n",
        "\r\n",
        "- average window : reduces noise\r\n",
        "\r\n",
        "**10. Differencing & Smoothing both past and present values**\r\n",
        "- remove trend and seasonality\r\n",
        "\r\n",
        "- ex. **use t - (t-365) values then we add the value of t-365 value**\r\n",
        "- remove noise in past -> use t - (t-365) values\r\n",
        "- moving average1 + moving average2\r\n",
        "- Trailing window / Centered Windows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZqIyTe43VZG"
      },
      "source": [
        "**11. Creating Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao9UPj9v0cfB",
        "outputId": "86dac35c-b9a8-43ea-a8ab-b17b7ff507d5"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.range(10)\r\n",
        "dataset = dataset.window(5, shift=1, drop_remainder=True)\r\n",
        "dataset = dataset.flat_map(lambda window : window.batch(5))\r\n",
        "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\r\n",
        "dataset = dataset.shuffle(buffer_size=10) # to avoid sequence bias (to remove the preference on the first item)\r\n",
        "dataset = dataset.batch(2).prefetch(1)\r\n",
        "\r\n",
        "for x, y in dataset:\r\n",
        "    print(\"x : \", x.numpy())\r\n",
        "    print(\"y : \", y.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x :  [[0 1 2 3]\n",
            " [5 6 7 8]]\n",
            "y :  [[4]\n",
            " [9]]\n",
            "x :  [[4 5 6 7]\n",
            " [2 3 4 5]]\n",
            "y :  [[8]\n",
            " [6]]\n",
            "x :  [[1 2 3 4]\n",
            " [3 4 5 6]]\n",
            "y :  [[5]\n",
            " [7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WpaT-eJ12Uo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}